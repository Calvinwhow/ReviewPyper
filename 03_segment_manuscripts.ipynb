{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Convert PDFs to Text\n",
    "\n",
    "Define path to master_list_pdf.csv from last step. Keeps files locked to data in spreadsheet.\n",
    "   - pdf_extractor.extract_text_from_master_list(path)\n",
    "\n",
    "Alternatively, you can simply point this at an entire directory full of PDFs with:\n",
    "   - pdf_extractor.extract_text_from_pdf_dir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/cu135/Dropbox (Partners HealthCare)/studies/CLOCC/search_results/master_list.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess Using Text Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1) Preprocess the PDF files with Texttractor (Fast, less generalizable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from calvin_utils.gpt_sys_review.pdf_utils import PDFTextExtractor\n",
    "# pdf_extractor = PDFTextExtractor()\n",
    "# pdf_extractor.extract_text_from_pdf_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2A) Extract Text Using Folder with PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from calvin_utils.gpt_sys_review.pdf_utils import OCROperator\n",
    "# output_dir = OCROperator.extract_text_from_pdf_dir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2B) Extract Text Using Master List\n",
    "- **This is the suggested method if you are using master_list.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting text from PDFs.: 100%|██████████| 52/52 [11:13<00:00, 12.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.gpt_sys_review.pdf_utils import OCROperator\n",
    "output_dir = OCROperator.extract_text_from_master_list(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 - Preprocess the Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing text files: 100%|██████████| 52/52 [00:00<00:00, 543.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.gpt_sys_review.txt_utils import TextPreprocessor\n",
    "# Initialize the TextPreprocessor class and preprocess the files\n",
    "preprocessor = TextPreprocessor(output_dir)\n",
    "preprocessed_path = preprocessor.process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03 - Label Text Sections\n",
    "- Article type 'case' will use GPT to convolve over the text with a cheap model and identify case-report sections\n",
    "- Article type 'research' will use keyword labelling to identify canonical article section like \"Methods\" or \"References\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Article type is either Case or Research\n",
    "article_type = \"case\" \n",
    "api_key_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/openai_key.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run\n",
    "- I will print a path out for you once this has run. Use that path for the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cu135/.local/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "Segmenting text files:  48%|████▊     | 25/52 [03:26<02:40,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: The server is overloaded or not ready yet.. Retrying Question No. 0 Attempt:(1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting text files: 100%|██████████| 52/52 [08:12<00:00,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: \n",
      " /Users/cu135/Dropbox (Partners HealthCare)/studies/CLOCC/search_results/pdf_txt/../preprocessed/../json/_case_labeled_sections.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from calvin_utils.gpt_sys_review.json_utils import SectionLabeler\n",
    "# Initialize the SectionLabeler class and process the files\n",
    "section_labeler = SectionLabeler(folder_path=preprocessed_path, article_type=article_type, api_key_path=api_key_path)\n",
    "section_labeler.process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your PDFs have preprocessed and segmented. \n",
    "\n",
    "- Enjoy. If this has been helpful, please consider adding Calvin Howard as a collaborator. \n",
    "- e: choward12@bwh.harvard.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.10 (nimlab)",
   "language": "python",
   "name": "nimlab_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
