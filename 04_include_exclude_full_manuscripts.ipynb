{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Provide Paths to Relevant Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI API Key Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key_path = \"/Users/cu135/Library/CloudStorage/OneDrive-Personal/OneDrive_Documents/Work/Software/Research/nimlab/gpt_document_reader/openai_key.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json_file_path is the path to the segmented JSON generated at the end of notebook 03. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"/Users/cu135/Dropbox (Partners HealthCare)/studies/review_pyper/raw_data/reviewpyper_validation/data_extraction_evaluation/labeled_text/case_labeled_sections.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Define Inclusion/Exclusion Questions\n",
    "\n",
    "Examples generated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.gpt_sys_review.gpt_utils import QuestionTemplate\n",
    "\n",
    "question_template = QuestionTemplate()\n",
    "question_template.inclusion_exclusion_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Critical Note**\n",
    "- You are going to define a dictionary with questions as keys (first) and outcomes as values (second).\n",
    "- The value determines if you are answering a positive question or a negative question.\n",
    "- If the question is positive (a yes is good), set the value to 1.\n",
    "- If the question is negative (a yes is bad), set the value to 0.\n",
    "- A good paper will be denoted by 1, with a bad paper denoted by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = {\n",
    "    \"Prioritizing implicit and explicit information, do you think this is a ______ case report or case series? (Yes/No)\": 1,\n",
    "    \"Prioritizing implicit and explicit information, do you think this is a case of transient amnesia, reversible amnesia, confabulation, epilepsy, toxicity, neurodegenerative disease, or functional/psychiatric neurological disorder? . (Yes/No)\": 0,\n",
    "    \"Prioritizing implicit and explicit information, do you think this examined both retrograde and anterograde amnesia? For example, if they report scores or a clinical examination examining retrograde and anterograde amnesia. (Yes/No)\": 1,\n",
    "    \"Prioritizing implicit and explicit information, do you think this has some sort of qualitative or quantitative measurments on memory severity? For example, a case with neuropsychological measurements on memory tests. (Yes/No)\": 1,\n",
    "    \"Prioritizing implicit and explicit information, do you think the memory loss might be due to global cognitive impairment? For example, a stroke resulting in executive, memory, language, and more changes is a global impairment. (Yes/No)\": 0,\n",
    "    \"Prioritizing implicit and explicit information, do you think this case report has a figure with neuroimaging? (Yes/No)\": 1,\n",
    "    \"Prioritizing implicit and explicit information, do you think this case report had brain atrophy, either focally or globally suggesting neurodegeneration? (Yes/No)\": 0,\n",
    "    \"Prioritizing implicit and explicit information, do you think this is due to atypical memory loss, where only a subset of memory is impaired? For example, if just spatial memory is lost. (Yes/No)\": 0,\n",
    "    \"Prioritizing implicit and explicit information, do you think this in English? (Yes/No)\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Ask Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the segmented labels you want to consider. \n",
    "\n",
    "- Article type 'case' will has sections 'case_report' and 'other'\n",
    "- Article type 'research' has sections \"Abstract\", \"Introduction\", \"Methods\", \"Results\", \"Discussion\", \"Conclusion\", \"References\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keys you want to consider (exclude 'References')\n",
    "keys_to_consider = [ \"case_report\" ]  # Add or remove keys as per your requirement\n",
    "\n",
    "# Define the type of article and questions\n",
    "article_type = \"case\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set test_mode=True during your first few runs, while you tune your questions to get the answers you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mode=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.gpt_sys_review.gpt_utils import OpenAIChatEvaluator\n",
    "evaluator = OpenAIChatEvaluator(api_key_path=api_key_path, json_file_path=json_file_path, keys_to_consider=keys_to_consider, question_type=article_type, model_choice=\"gpt4\",  question=question, test_mode=test_mode)\n",
    "answers = evaluator.evaluate_all_files()\n",
    "new_json_path = evaluator.save_to_json(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Summarize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calvin_utils.gpt_sys_review.json_utils import InclusionExclusionSummarizer\n",
    "summarizer = InclusionExclusionSummarizer(new_json_path, questions=question)\n",
    "result_df, raw_path, automated_path = summarizer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your articles have been completely evaluated and filtered. \n",
    "\n",
    "Please check the CSVs in the directory noted above and use the path to the one you would like to use. It will be for your next notebook.\n",
    "- Enjoy. If this has been helpful, please consider adding Calvin Howard as a collaborator. \n",
    "- e: choward12@bwh.harvard.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reviewpyper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
